{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PredictEmailOpens.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtnyCqspKIofybJgqz2AQi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbCCCEAEI1l2"
      },
      "source": [
        "Predict whether a user opens the email or ignores it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4_P1qmtIzev"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model, Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi7_c3ZxI6wF"
      },
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTZO8ObjI8AE"
      },
      "source": [
        "users_info = pd.read_csv('users.csv')\n",
        "users_info.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZL5LwCmI77y"
      },
      "source": [
        "# no null values for train.csv but we see many for user.csv\n",
        "print(data.isnull().sum())\n",
        "print()\n",
        "print(users_info.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w3YBOdDI75S"
      },
      "source": [
        "data.grass_date.value_counts() #which day of the week"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeALDiO4JSyj"
      },
      "source": [
        "print(data.last_open_day.value_counts().sort_index(ascending=False))\n",
        "print()\n",
        "print(data.last_login_day.value_counts().sort_index(ascending=False))\n",
        "print()\n",
        "print(data.last_checkout_day.value_counts().sort_index(ascending=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sqXxE_XI72t"
      },
      "source": [
        "# class size - imbalanced, we will need to use MCC for measurement instead of simple accuracy\n",
        "data.open_flag.value_counts().plot(kind='bar');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbCC_l3eI7zS"
      },
      "source": [
        "users_info.age.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESAa1zDII7vJ"
      },
      "source": [
        "def preprocess_data(raw_data):\n",
        "    \"\"\"\n",
        "    This function cleans the data from train.csv \n",
        "    \"\"\"\n",
        "    processed_data = raw_data.copy()\n",
        "    \n",
        "    processed_data['last_open_day'] = processed_data['last_open_day'].apply(lambda x: -1 if x == \"Never open\" else int(x))\n",
        "    processed_data['last_login_day'] = processed_data['last_login_day'].apply(lambda x: -1 if x == \"Never login\" else int(x))\n",
        "    processed_data['last_checkout_day'] = processed_data['last_checkout_day'].apply(lambda x: -1 if x == \"Never checkout\" else int(x))\n",
        "    \n",
        "    # transform date of email sent into day of the week (0-6)\n",
        "    processed_data['grass_date'] = processed_data['grass_date'].apply(lambda x: pd.to_datetime(x[:10]))\n",
        "    processed_data['grass_date'] = processed_data['grass_date'].dt.dayofweek\n",
        "    \n",
        "    return processed_data\n",
        "\n",
        "def preprocess_users(raw_users_data):\n",
        "    \"\"\"\n",
        "    This function cleans the data from users.csv\n",
        "    \"\"\"\n",
        "    processed_users = raw_users_data.copy()\n",
        "    \n",
        "    # handle null values in user.csv\n",
        "    processed_users['attr_1'] = processed_users['attr_1'].apply(lambda x: -1 if np.isnan(x) else int(x))\n",
        "    processed_users['attr_2'] = processed_users['attr_2'].apply(lambda x: -1 if np.isnan(x) else int(x))\n",
        "    processed_users['attr_3'] = processed_users['attr_3'].apply(lambda x: -1 if np.isnan(x) else int(x))\n",
        "    processed_users['age'] = processed_users['age'].apply(lambda x: -1 if np.isnan(x) else int(x))\n",
        "    \n",
        "    # make one-hot encoding for email domains\n",
        "    processed_users = pd.get_dummies(processed_users, columns=['domain']) \n",
        "    \n",
        "    return processed_users"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3mNDKA6I7s1"
      },
      "source": [
        "processed_data, processed_user = preprocess_data(data), preprocess_users(users_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHR1ARjvI7qZ"
      },
      "source": [
        "print(processed_data.info())\n",
        "print()\n",
        "print(processed_user.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXGveqbGI7n3"
      },
      "source": [
        "merged_data = pd.merge(left=processed_data, right=processed_user, how='left', left_on='user_id', right_on='user_id')\n",
        "merged_data\n",
        "print(merged_data.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2k9lLjmJ5xc"
      },
      "source": [
        "Perhaps PCA can be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzUDzvJRI7li"
      },
      "source": [
        "merged_data.drop(columns=['row_id'], inplace=True)\n",
        "merged_data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXcz1b67I7g9"
      },
      "source": [
        "merged_data_corr = merged_data.corr()\n",
        "merged_data_corr['open_flag'] # corr coeff for each feature wrt to open_flag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt2LmWKGKCVC"
      },
      "source": [
        "\n",
        "It seems like our target open_flag does not really seem to depend on that many features in our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I36YNpgzI7ex"
      },
      "source": [
        "# 'RdBu_r', BrBG', 'coolwarm' are good diverging colormaps\n",
        "merged_data_corr.style.background_gradient(cmap='RdBu_r').set_precision(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7HLVzFTI7cq"
      },
      "source": [
        "def email_clfr(nb_features, nb_hidden_layers, nb_hidden_units, learning_rate):\n",
        "    \"\"\"\n",
        "    This function creates the classification model based on the given hyperparameters\n",
        "    \"\"\"\n",
        "    if nb_hidden_layers != len(nb_hidden_units):\n",
        "        print(\"List size of hidden_units must equal to hidden_layers\")\n",
        "        return None\n",
        "    \n",
        "    else:\n",
        "        model = Sequential()\n",
        "        for layer in range(nb_hidden_layers):\n",
        "            if layer == 0:\n",
        "                model.add(Dense(units=nb_hidden_units[layer], input_shape=(nb_features,), activation='relu'))\n",
        "            else:\n",
        "                model.add(Dense(units=nb_hidden_units[layer], activation='relu'))\n",
        "                \n",
        "        model.add(Dense(units=1, activation='sigmoid'))\n",
        "        \n",
        "        model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics = ['accuracy', matthews_correlation])\n",
        "        \n",
        "        print(model.summary())\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uJ3tFi3KLEG"
      },
      "source": [
        "# custom metric for evaluation of imbalanced dataset\n",
        "def matthews_correlation(y_true, y_pred):\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos\n",
        "\n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    tn = K.sum(y_neg * y_pred_neg)\n",
        "\n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg)\n",
        "\n",
        "    numerator = (tp * tn - fp * fn)\n",
        "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "\n",
        "    return numerator / (denominator + K.epsilon())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqtpimSVKLAz"
      },
      "source": [
        "y = merged_data.iloc[:,16:17]\n",
        "X = merged_data.drop(columns=['open_flag'],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGULEnlPI7aW"
      },
      "source": [
        "X = X[['country_code',\n",
        "       'last_open_day', \n",
        "       'open_count_last_10_days', \n",
        "       'open_count_last_30_days', \n",
        "       'open_count_last_60_days',\n",
        "       'attr_1', \n",
        "       'attr_2', \n",
        "       'attr_3',\n",
        "       'domain_@163.com', \n",
        "       'domain_@gmail.com', \n",
        "       'domain_@hotmail.com',\n",
        "       'domain_@icloud.com', \n",
        "       'domain_@live.com', \n",
        "       'domain_@outlook.com',\n",
        "       'domain_@qq.com', \n",
        "       'domain_@rocketmail.com', \n",
        "       'domain_@yahoo.com',\n",
        "       'domain_@ymail.com', \n",
        "       'domain_other']]\n",
        "X.columns\n",
        "print(len(X.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72S47dWBI7YP"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range = (0,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl7jNso5I7Vy"
      },
      "source": [
        "X_scaled = scaler.fit_transform(X)\n",
        "print(X_scaled.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vndtHx7VKbaR"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.30, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-MnSY6PKjBC"
      },
      "source": [
        "print(\"X_train shape: \" + str(X_train.shape))\n",
        "print(\"y_train shape: \" + str(y_train.shape))\n",
        "print()\n",
        "print(\"X_test shape: \" + str(X_test.shape))\n",
        "print(\"y_test shape: \" + str(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_DIjcEKbXM"
      },
      "source": [
        "# Early stopping\n",
        "es = EarlyStopping(monitor='matthews_correlation', mode='max', verbose=1, patience=2000)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_matthews_correlation', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc7VnSCxKbSL"
      },
      "source": [
        "classifier = email_clfr(nb_features=19, nb_hidden_layers=5, nb_hidden_units=[10,10,10,10,10], learning_rate=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpfo3ho5KbMm"
      },
      "source": [
        "history = classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 20000, batch_size = 1024, callbacks = [es,mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoRhyEhbKbJo"
      },
      "source": [
        "#load the saved model\n",
        "saved_model = load_model('best_model.h5', custom_objects={'matthews_correlation': matthews_correlation})\n",
        "\n",
        "# evaluate the model\n",
        "_, train_acc, train_mcc = saved_model.evaluate(X_train, y_train, verbose=0)\n",
        "_, test_acc, test_mcc = saved_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"Train Acc: \" + str(train_acc))\n",
        "print(\"Train MCC: \" + str(train_mcc))\n",
        "print()\n",
        "print(\"Test Acc: \" + str(test_acc))\n",
        "print(\"Test MCC: \" + str(test_mcc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OlmRG9uK-QA"
      },
      "source": [
        "test_data = pd.read_csv('test.csv')\n",
        "processed_test = preprocess_data(test_data)\n",
        "\n",
        "merged_test_data = pd.merge(left=processed_test, right=processed_user, how='left', left_on='user_id', right_on='user_id')\n",
        "merged_test_data\n",
        "\n",
        "merged_test_data.drop(columns=['row_id','age'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF4ftx6lK-Ma"
      },
      "source": [
        "merged_test_data = merged_test_data[['country_code', \n",
        "                                     'last_open_day', \n",
        "                                     'open_count_last_10_days', \n",
        "                                     'open_count_last_30_days',\n",
        "                                     'open_count_last_60_days',\n",
        "                                     'attr_1', \n",
        "                                     'attr_2', \n",
        "                                     'attr_3',\n",
        "                                     'domain_@163.com', \n",
        "                                     'domain_@gmail.com', \n",
        "                                     'domain_@hotmail.com',\n",
        "                                     'domain_@icloud.com', \n",
        "                                     'domain_@live.com', \n",
        "                                     'domain_@outlook.com',\n",
        "                                     'domain_@qq.com', \n",
        "                                     'domain_@rocketmail.com', \n",
        "                                     'domain_@yahoo.com',\n",
        "                                     'domain_@ymail.com', \n",
        "                                     'domain_other']]\n",
        "merged_test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrUVy5PaK-E3"
      },
      "source": [
        "scaled_test = scaler.fit_transform(merged_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsskGeb3LDhu"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoqE20vSK99t"
      },
      "source": [
        "open_flags = saved_model.predict(scaled_test)\n",
        "open_flags = (open_flags[:,0] > .5).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze6jNxGpLFUn"
      },
      "source": [
        "submission = pd.DataFrame({\"row_id\": test_data['row_id'],\n",
        "                           \"open_flag\": open_flags})\n",
        "\n",
        "submission.to_csv(\"submission_15.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPSFKk6JLFRo"
      },
      "source": [
        "# save weights only\n",
        "classifier.save_weights('classifier_15.h5')\n",
        "\n",
        "# save architecture only\n",
        "model_architecture = classifier.to_json()\n",
        "with open('classifier_15.json','w') as json_file:\n",
        "    json_file.write(model_architecture)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnE7UWYsK96O"
      },
      "source": [
        "# # Load model architecture and weights\n",
        "# from keras.models import model_from_json\n",
        "# with open('Final_Model_architecture.json','r') as json_file:\n",
        "#     architecture = json_file.read()\n",
        "    \n",
        "# model = model_from_json(architecture)\n",
        "# model.load_weights('Final_Model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZEf8rW8K93G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}