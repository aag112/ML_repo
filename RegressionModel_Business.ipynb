{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RegressionModel-Business.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTMIZ3btAX2EdDrq+IwhkK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yThy2gSuWkd"
      },
      "source": [
        "\"\"\"\n",
        "This script reads trains and evaluates a logistic regression model prediction the probability for business closure.\n",
        "The prediction is made based of all attributes and on subsets of attributes containing only most important attributes.\n",
        "plot the ROC curve, feature importance and a report file containing some performance metrics for all of the models\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLkexYRsulBG"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, roc_curve, roc_auc_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.inspection import permutation_importance\n",
        "import argparse\n",
        "import json\n",
        "from pathlib import Path\n",
        "from matplotlib import rcParams\n",
        "from tabulate import tabulate\n",
        "rcParams.update({'figure.autolayout': True})\n",
        "\n",
        "sns.set_context(\"talk\", font_scale=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqxxq0HmuxEQ"
      },
      "source": [
        "class Model:\n",
        "    \"\"\"\n",
        "    A class containing the model and data sets\n",
        "    Attributes\n",
        "    ----------\n",
        "    x : dataframe\n",
        "        a dataframe contraining all attributes\n",
        "    y : series\n",
        "        a series contraining all labels\n",
        "    smote : object\n",
        "        smote object for balancing the training data\n",
        "    model : object\n",
        "        logistic regression model\n",
        "    allAttributes : list\n",
        "        name of all attributes\n",
        "    currentAttributes : list\n",
        "        name of attributes currently used\n",
        "    meanF1Score : float\n",
        "        metric: F1 score\n",
        "    AuRScore : float\n",
        "        metric: area under ROC curve score\n",
        "    cnfMatrix : list\n",
        "        confusion matrix\n",
        "    clasResport : dict\n",
        "        dict containing the classification report\n",
        "    ROC : list\n",
        "        ROC curve\n",
        "    PerbImp : list\n",
        "        permutation importance of current attributes\n",
        "    PerbImpMeanDict : dict\n",
        "        dict containing permutation importance of current attributes\n",
        "    Methods\n",
        "    -------\n",
        "    splitDataset()\n",
        "        split the data set in training and test subsets\n",
        "    update()\n",
        "        train, test and eval model\n",
        "    plot()\n",
        "        plot feature importance and ROC vurve\n",
        "    restrictAttribute()\n",
        "        use only a subset of attributes\n",
        "    evalPerformance()\n",
        "        evaluate model performance\n",
        "    createPerformanceReport()\n",
        "        create a text file containing important performance metrics and feature importance\n",
        "    plotFeatureImportance()\n",
        "        plot feature impoirtance\n",
        "    plotROC()\n",
        "        plot ROC curve\n",
        "    calcPerbImp()\n",
        "        calculate permutation importance of attributes\n",
        "    balanceDataset()\n",
        "        balance training set with SMOTE\n",
        "    fitModel()\n",
        "        fit logistic regression model\n",
        "    predictTestData()\n",
        "        predict test data\n",
        "    \"\"\"\n",
        "    def __init__(self, x, y,basefolder, testSplit= 0.2, seed = 0, PerbImp_repeats = 20):\n",
        "        self.seed = seed\n",
        "        self.basefolder = basefolder\n",
        "        self.PerbImp_repeats = PerbImp_repeats\n",
        "        self.model = LogisticRegression()\n",
        "        self.smote = SMOTE(random_state=self.seed)\n",
        "        self.testSplit = testSplit\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.nameLable = y.name\n",
        "        self.allAttributes = x.columns\n",
        "        self.currentAttributes = self.allAttributes\n",
        "        self.splitDataset()\n",
        "        self.update()\n",
        "\n",
        "    def splitDataset(self):\n",
        "        self.trainX, self.testX, self.trainY, self.testY = \\\n",
        "            train_test_split(StandardScaler().fit_transform(self.x[self.currentAttributes]),\n",
        "                             self.y, test_size=self.testSplit, random_state=self.seed)\n",
        "        self.balanceDataset()\n",
        "\n",
        "    def plot(self, folder):\n",
        "        self.plotFeatureImportance(folder)\n",
        "        self.plotROC(folder)\n",
        "\n",
        "    def update(self):\n",
        "        self.fitModel()\n",
        "        self.predictTestData()\n",
        "        self.calcPerbImp()\n",
        "        self.evalPerformance()\n",
        "\n",
        "    def restrictAttribute(self, Attributes):\n",
        "        self.currentAttributes = Attributes\n",
        "        self.splitDataset()\n",
        "        self.update()\n",
        "\n",
        "    def evalPerformance(self):\n",
        "        self.meanF1Score= f1_score(self.testY, self.testY_pred, average=\"macro\")\n",
        "        self.AuRScore = roc_auc_score(self.testY, self.testY_predProb[:, 1])\n",
        "        self.cnfMatrix = confusion_matrix(self.testY, self.testY_pred)\n",
        "        self.clasResport = classification_report(self.testY, self.testY_pred, output_dict=True)\n",
        "        self.ROC = roc_curve(self.testY, self.testY_predProb[:, 1])\n",
        "\n",
        "    def createPerformanceReport(self, folder):\n",
        "        path = os.path.join(self.basefolder,folder, \"performanceReport.txt\")\n",
        "        file1 = open(path, \"a\")\n",
        "\n",
        "        AttStr = \"Used Attributes: \"   + ('; '.join(str(x) for x in self.currentAttributes))\n",
        "        file1.write(AttStr + \"\\n\\n\")\n",
        "\n",
        "        file1.write('Area under ROC = %.3f' % (self.meanF1Score) + \"\\n\")\n",
        "        file1.write('Mean F1 Score = %.3f' % (self.AuRScore) + \"\\n\\n\")\n",
        "\n",
        "        file1.write('Total Samples = %.3f' % (len(self.x)) + \"\\n\")\n",
        "        file1.write('Positive Samples = %.3f' % (len(self.y[self.y == 1])) + \"\\n\")\n",
        "        file1.write('Negative Samples = %.3f' % (len(self.y[self.y == 0])) + \"\\n\\n\")\n",
        "\n",
        "        df = pd.DataFrame(self.clasResport).transpose()\n",
        "        tab = tabulate(df, headers='keys', tablefmt='psql')\n",
        "        file1.write(tab + \"\\n\")\n",
        "\n",
        "        file1.write(\"\\n\\n\" + \"Permutation Importance of Attributes\" + \"\\n\")\n",
        "        df = pd.DataFrame(\n",
        "            self.PerbImpMeanDict, index=[\"Permutation Importance\"]\n",
        "        ).T.sort_values(by=[\"Permutation Importance\"],ascending=False)\n",
        "        df[\"Permutation Importance Normalized\"] = df[\"Permutation Importance\"].apply(\n",
        "            lambda x: x / df[\"Permutation Importance\"].sum() * 100\n",
        "        )\n",
        "        df = df.round({'Permutation Importance': 4, \"Permutation Importance Normalized\": 1})\n",
        "        tab = tabulate(df, headers='keys', tablefmt='psql')\n",
        "        file1.write(tab + \"\\n\")\n",
        "\n",
        "        file1.write(\"\\n\\n\" + \"Confusion Matrix\"  + \"\\n\")\n",
        "        df = pd.DataFrame(self.cnfMatrix, index=[\"0\",\"1\"])\n",
        "        tab = tabulate(df, headers='keys', tablefmt='psql')\n",
        "        file1.write(tab + \"\\n\")\n",
        "        file1.close()\n",
        "\n",
        "    def plotFeatureImportance(self,folder = \"\"):\n",
        "        fig = plt.figure()\n",
        "        plt.bar(range(len(self.PerbImpMeanDict)), sorted(self.PerbImpMeanDict.values(), reverse=True), align='center')\n",
        "        plt.xticks(range(len(self.PerbImpMeanDict)), sorted(self.PerbImpMeanDict, key=self.PerbImpMeanDict.get, reverse=True))\n",
        "        plt.xticks(rotation=75)\n",
        "        plt.ylabel('Permutation Feature Importance')\n",
        "        path = os.path.join(self.basefolder, folder)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        path =  os.path.join(path, 'permutation_importance.png')\n",
        "        fig.savefig(path)\n",
        "\n",
        "    def plotROC(self,folder = \"\", label = \"ROC Curve\"):\n",
        "        path = os.path.join(self.basefolder, folder)\n",
        "        plotSummaryROC([self.ROC], folder = path, labels=[label])\n",
        "\n",
        "    def calcPerbImp(self):\n",
        "        self.PerbImp = permutation_importance(\n",
        "            self.model, self.testX, self.testY, scoring='neg_mean_squared_error',\n",
        "            random_state=self.seed,n_repeats=self.PerbImp_repeats\n",
        "        )\n",
        "        self.PerbImpMean = self.PerbImp.importances_mean\n",
        "        self.PerbImpMeanDict = dict(zip(self.currentAttributes, self.PerbImpMean.tolist()))\n",
        "\n",
        "    def balanceDataset(self):\n",
        "        trainX_res, trainY_res = self.smote.fit_resample(self.trainX, self.trainY)\n",
        "        self.trainX_res = pd.DataFrame(trainX_res)\n",
        "        self.trainY_res = pd.DataFrame(trainY_res)\n",
        "\n",
        "    def fitModel(self):\n",
        "        self.model.fit(self.trainX_res, self.trainY_res.values.ravel())\n",
        "\n",
        "    def predictTestData(self):\n",
        "        self.testY_pred = self.model.predict(self.testX)\n",
        "        self.testY_predProb = self.model.predict_proba(self.testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOv3nuc0t2jA"
      },
      "source": [
        "def parse_arguments():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--inputname', type=str, default=None, help=\"Name of data file\", required=True)\n",
        "    parser.add_argument('--NameLable', type=str, default=\"is_open\", help=\"name of label\", required=False)\n",
        "    parser.add_argument('--folder', type=str, default=\"mount\", help=\"Relative path of folder to operate in\", required=False)\n",
        "    return parser.parse_args()\n",
        "\n",
        "def plotSummaryROC(ROCList, folder, labels):\n",
        "    fig = plt.figure()\n",
        "    line = np.linspace(0,1,11)\n",
        "    plt.plot(line, line, linestyle='--', color = \"black\")\n",
        "    color = reversed(sns.color_palette(\"GnBu\", len(labels)+2))#\"PuBu\"\n",
        "    for R, l, c in zip(ROCList, labels, color):\n",
        "        plt.plot(R[0], R[1], marker= None, color = c, label=l, markersize=2)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend()\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "    path = os.path.join(folder, 'ROC.png')\n",
        "    fig.savefig(path, bbox_inches='tight')\n",
        "\n",
        "def main(args):\n",
        "    folder = os.path.normpath(os.path.join(os.getcwd(), args.folder))\n",
        "    path = os.path.join(folder, args.inputname)\n",
        "    df = pickle.load(open(path, \"rb\"))\n",
        "    string = \"run_\" + str(datetime.now()).replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\").replace(\"'\", \"_\")\n",
        "    basefolder = os.path.join(folder, string)\n",
        "    LogRegModel = Model(y = df[args.NameLable], x = df.drop([args.NameLable], axis=1), basefolder = basefolder)\n",
        "    LogRegModel.plot(folder = \"All_Attributes\")\n",
        "    LogRegModel.createPerformanceReport(folder = \"All_Attributes\")\n",
        "    ROC = [LogRegModel.ROC]\n",
        "    Labels = [\"All_Attributes\"]\n",
        "    PerbImpDict = LogRegModel.PerbImpMeanDict\n",
        "    for i in [10, 5, 3, 1]:\n",
        "        LogRegModel.restrictAttribute(sorted(PerbImpDict, key=PerbImpDict.get, reverse=True)[:i])\n",
        "        label = \"Top_\" + str(i) + \"_Attribute\"\n",
        "        LogRegModel.plot(folder=label)\n",
        "        Labels.append(label)\n",
        "        ROC.append(LogRegModel.ROC)\n",
        "    plotSummaryROC(ROCList = ROC, folder = basefolder, labels = Labels)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = parse_arguments()\n",
        "    main(args)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}